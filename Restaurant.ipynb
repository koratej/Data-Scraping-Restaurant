{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# TEAM\n",
        "# 1. Likhita\n",
        "# 2. Harshitha\n",
        "# 3. Soundarya\n",
        "# 4. Ravi Teja\n",
        "# 5. Pavan\n",
        "# 6. Sriram\n",
        "# 7. Kondaiah"
      ],
      "metadata": {
        "id": "Wede2lR1P6-e"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "import time"
      ],
      "metadata": {
        "id": "xL-r94Zfz6Jl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = 'https://m.yelp.com/search'\n",
        "location = 'San+Francisco%2C+CA'\n",
        "pages = 24\n",
        "\n",
        "result = {}\n",
        "\n",
        "\n",
        "for page in range(1, pages + 1):\n",
        "    params = {\n",
        "        'find_desc': '',\n",
        "        'find_loc': location,\n",
        "        'start': (page-1) * 10\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    for restaurant in soup.find_all('a', class_='css-19v1rkv'):\n",
        "      html = str(restaurant)\n",
        "      soup = BeautifulSoup(html, 'html.parser')\n",
        "      company_name = soup.get_text()\n",
        "      result[company_name] = {}\n",
        "      print('company_name : ',company_name)\n",
        "\n",
        "\n",
        "      hyper_link = 'https://www.yelp.com' + soup.find('a')['href']\n",
        "      # print('hyper_link  : ',hyper_link)\n",
        "\n",
        "      page_num = 1\n",
        "\n",
        "      while True:\n",
        "\n",
        "        page_url = hyper_link + '?start=' + str((page_num - 1) * 10)\n",
        "        print(page_url)\n",
        "        response = requests.get(page_url)\n",
        "        html_content = response.content\n",
        "        html_content = str(html_content)\n",
        "        hyper_link_soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "        usernames = []\n",
        "        reviews = []\n",
        "\n",
        "\n",
        "        for restaurant in hyper_link_soup.find_all('span', class_='fs-block css-ux5mu6'):\n",
        "            html = str(restaurant)\n",
        "            user_name_soup = BeautifulSoup(html, 'html.parser')\n",
        "            user_name = user_name_soup.get_text()\n",
        "            if user_name != 'Username':\n",
        "                usernames.append(user_name)\n",
        "                # print(user_name)\n",
        "\n",
        "\n",
        "        hyper_link_soup_1 = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "        for review_links in hyper_link_soup_1.find_all(\"span\", class_=\"raw__09f24__T4Ezm\", lang=\"en\"):\n",
        "          html = str(review_links)\n",
        "          review_soup = BeautifulSoup(html, \"html.parser\")\n",
        "          review_text = review_soup.get_text().replace('\\\\xc2\\\\xa0','')\n",
        "          reviews.append(review_text)\n",
        "          # print(review_text)\n",
        "\n",
        "\n",
        "        for i in range(len(usernames)):\n",
        "            result[company_name][usernames[i]] = reviews[i]\n",
        "\n",
        "\n",
        "        next_page_link = hyper_link_soup.find('a', class_='next-link')\n",
        "\n",
        "        if next_page_link is None:\n",
        "          break\n",
        "        else:\n",
        "          time.sleep(2)\n",
        "          page_num += 1\n",
        "\n",
        "\n",
        "with open('Yelp_reviews.json','w') as json_file:\n",
        "  json.dump(result,json_file)\n",
        "\n",
        "print(\"DONE DATA SAVED\")"
      ],
      "metadata": {
        "id": "ZSMLu7lZMKRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb5bbe1-5bda-47dc-a18e-a63072dd4f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "company_name :  Fog Harbor Fish House\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=0\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=10\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=20\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=30\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=40\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=50\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=60\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=70\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=80\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=90\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=100\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=110\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=120\n",
            "https://www.yelp.com/biz/fog-harbor-fish-house-san-francisco-2?start=130\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}